{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5318b90b2dc437db5eef9efcd838340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cab0c818a7a488782cb11d79edafc43",
              "IPY_MODEL_c523e1cee771448cae6d00c92d8d4dfd",
              "IPY_MODEL_c6690a2cb60f4e66b4ad2f66bded1540"
            ],
            "layout": "IPY_MODEL_ca855995b152403996565a9ca7f11491"
          }
        },
        "8cab0c818a7a488782cb11d79edafc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb07ab0f0cab4485aea256f484a6c97f",
            "placeholder": "​",
            "style": "IPY_MODEL_69b7bf6c5d5545a4bac9b2ebd5c678c2",
            "value": "Downloading builder script: "
          }
        },
        "c523e1cee771448cae6d00c92d8d4dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f0659018fdd41798321cac84319dd1d",
            "max": 2832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_436b3599f6dd422d8a032acd7c805440",
            "value": 2832
          }
        },
        "c6690a2cb60f4e66b4ad2f66bded1540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290cf3de8a3c40afae3d0bb464e14af7",
            "placeholder": "​",
            "style": "IPY_MODEL_a018475e109c497c9d6951b2adae1840",
            "value": " 8.47k/? [00:00&lt;00:00, 393kB/s]"
          }
        },
        "ca855995b152403996565a9ca7f11491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb07ab0f0cab4485aea256f484a6c97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b7bf6c5d5545a4bac9b2ebd5c678c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f0659018fdd41798321cac84319dd1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436b3599f6dd422d8a032acd7c805440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "290cf3de8a3c40afae3d0bb464e14af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a018475e109c497c9d6951b2adae1840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Load required libraries"
      ],
      "metadata": {
        "id": "ahMP1n5Dt1nL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftqgzJgXrX-r",
        "outputId": "37e1d79b-63c6-4c53-f212-f2c8fbb4fe47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu117/\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.25.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.6)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.1)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.36.2)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.15.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Requirement already satisfied: loralib==0.1.1 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U transformers peft accelerate optimum\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/\n",
        "!pip install -q datasets\n",
        "!pip install loralib==0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig\n",
        "import torch\n",
        "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "U-O9Yp5bta35"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load quantized model using PEFT"
      ],
      "metadata": {
        "id": "LM79-uqUuD0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the model ID to be loaded:\n",
        "\n",
        "model_id = \"TheBloke/Llama-2-7b-Chat-GPTQ\"\n",
        "\n",
        "# Define the quantization configuration:\n",
        "gptq_config  = GPTQConfig(bits=4  # Quantize model weights to 4 bits for reduced size and faster inference.\n",
        "                          , disable_exllama=True) # disabled the exllama kernel because training with exllama kernel is unstable\n",
        "\n",
        "# Load the quantized model:\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             quantization_config=gptq_config ,\n",
        "                                             device_map=\"auto\", # Automatically distribute the model across available devices (if applicable)\n",
        "                                             trust_remote_code=True) # Necessary for loading models with custom code components."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oblVqlfBuPRY",
        "outputId": "f9858005-75ec-4508-bcfe-b3b3d89a7cfd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the appropriate tokenizer for the specified model:\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "NsYUpgn20GQg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.quantization_config.to_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QjadqPHur6x",
        "outputId": "120b6553-c5ab-4ce4-f824-340ba857a8e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'quant_method': <QuantizationMethod.GPTQ: 'gptq'>,\n",
              " 'bits': 4,\n",
              " 'tokenizer': None,\n",
              " 'dataset': None,\n",
              " 'group_size': 128,\n",
              " 'damp_percent': 0.01,\n",
              " 'desc_act': False,\n",
              " 'sym': True,\n",
              " 'true_sequential': True,\n",
              " 'use_cuda_fp16': False,\n",
              " 'model_seqlen': None,\n",
              " 'block_name_to_quantize': None,\n",
              " 'module_name_preceding_first_block': None,\n",
              " 'batch_size': 1,\n",
              " 'pad_token_id': None,\n",
              " 'use_exllama': False,\n",
              " 'max_input_length': None,\n",
              " 'exllama_config': {'version': <ExllamaVersion.ONE: 1>},\n",
              " 'cache_block_outputs': True}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable() # Activate gradient checkpointing for memory optimization during training.\n",
        "model = prepare_model_for_kbit_training(model) # Apply necessary modifications for K-bit training"
      ],
      "metadata": {
        "id": "2H2wFxc7utSg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=8 # Set the rank for low-rank attention approximation\n",
        "alpha=32 # Set the scaling factor for attention scores\n",
        "dropout=0.05 # Set the dropout rate for regularization\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=r,\n",
        "    lora_alpha=alpha,\n",
        "    target_modules=[\"k_proj\",\"o_proj\",\"q_proj\",\"v_proj\"],  # Apply LoRA to these specific projection modules.\n",
        "    lora_dropout=dropout,\n",
        "    bias=\"none\",    # Disable biases in attention modules\n",
        "    task_type=\"CAUSAL_LM\"  # Specify the model's task as causal language modeling.\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)  # Apply PEFT (Predictive Efficient Fine-Tuning) to the model using the LoRA configuration.\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VGKUJe2uvCh",
        "outputId": "7fa866af-e199-4911-b451-a1fcaae37044"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 8,388,608 || all params: 270,798,848 || trainable%: 3.097726619575575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the dataset"
      ],
      "metadata": {
        "id": "S977V73Iv4yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "data = load_dataset(\"ttbui/alpaca_webgen_html\", split=\"train\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAsKTAxxv6oQ",
        "outputId": "ca24b639-1abe-4b2c-f8f4-f655a70d6c26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['output', 'input', 'instruction'],\n",
              "    num_rows: 528\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(dataset):\n",
        "  #Data Structure Check:\n",
        "    if \"instruction\" in dataset and \"output\" in dataset:\n",
        "    #Prompt Construction:\n",
        "      prompt_template = \"Below is instruction that describes a task to code in HTML,what is output in HTML: \\n \\n'\"\n",
        "      instruction = dataset[\"instruction\"][0]\n",
        "      response = dataset[\"output\"][0]\n",
        "\n",
        "      text_with_prompt = (prompt_template +\n",
        "                          '### Instruction: \\n' +instruction +\n",
        "                          '\\n ### Response: \\n' + response)\n",
        "\n",
        "    #Tokenization\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Set padding token to the end-of-sentence token\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text_with_prompt,\n",
        "        return_tensors=\"np\",   #Return NumPy tensors\n",
        "        padding=True,    #Pad sequences to equal length\n",
        "    )\n",
        "\n",
        "    max_length = min(\n",
        "        tokenized_inputs[\"input_ids\"].shape[1],\n",
        "        2048    # Set maximum length to 2048 or the actual length, whichever is shorter\n",
        "    )\n",
        "    tokenizer.truncation_side = \"left\"  # Truncate from the left if necessary\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text_with_prompt,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,   # Enable truncation\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "jujOeEDIwhRP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization Mapping\n",
        "tokenized_dataset = data.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    drop_last_batch=True\n",
        ")"
      ],
      "metadata": {
        "id": "5uVSF-WH0DFD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vnHtkJl1abB",
        "outputId": "73bb16a3-71c8-426b-e45d-e2f175c2611a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['output', 'input', 'instruction', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 528\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting into Testing and training sets\n",
        "data_split = tokenized_dataset.train_test_split(test_size=0.25, shuffle=True, seed=123)\n",
        "data_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dT8Ogi11hUI",
        "outputId": "0cf2a406-7878-45e2-ed47-61ea3b2b48e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['output', 'input', 'instruction', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 396\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['output', 'input', 'instruction', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 132\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check base model results"
      ],
      "metadata": {
        "id": "Ch3sVhTuFTxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_exact_match(a, b):\n",
        "    return a.strip() == b.strip()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",\n",
        "          truncation=True,\n",
        "          max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ],
      "metadata": {
        "id": "eKXPmtfeFRxJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a specific test question from the dataset:\n",
        "test_question = data_split[\"test\"]['instruction'][2]\n",
        "\n",
        "# Generate an answer using the model and tokenizer:\n",
        "generated_answer = inference(test_question, model, tokenizer)\n",
        "\n",
        "print(test_question)\n",
        "print(generated_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F9VUp0EFqzp",
        "outputId": "cd50129d-de5e-4985-b6ff-daebef9acaec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create a simple HTML webpage without using any external stylesheets.\n",
            "\n",
            "\n",
            "Create a simple HTML webpage without using any external stylesheets. The webpage should have a header, a paragraph of text, and a link to another webpage.\n",
            "\n",
            "Here is the HTML code for the webpage:\n",
            "```\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "  <head>\n",
            "    <title>My Simple HTML Page</title>\n",
            "  </head>\n",
            "  <body>\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "x_D6lPId17wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set padding token for consistent length handling:\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Create a Trainer instance for model training:\n",
        "trainer = Trainer(\n",
        "    model=model,                          # Specify the model to be trained\n",
        "    train_dataset=data_split[\"train\"],\n",
        "    args=TrainingArguments(               # Configure training settings\n",
        "        per_device_train_batch_size=2,    # Process 1 batch per device per gradient update.\n",
        "        gradient_accumulation_steps=4,    # Accumulate gradients over 4 steps for effective batch size of 4.\n",
        "        warmup_steps=2,                   # Gradually increase learning rate over 2 initial steps.\n",
        "        max_steps=100,                     # Train for a maximum of 10 steps (adjust for actual training).\n",
        "        learning_rate=2e-4,               # Set the learning rate\n",
        "        fp16=True,                        # Enable mixed-precision training for potential speedup.\n",
        "        logging_steps=3,                  # Log training progress every step.\n",
        "        output_dir=\"outputs_dirc\",        # Save model checkpoints and logs in the \"outputs_dirc\" directory\n",
        "        optim=\"adamw_torch\",              # PyTorch implementation\n",
        "        ),\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)  # Prepare text inputs for language modeling\n",
        ")"
      ],
      "metadata": {
        "id": "-NIDZam42DOs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1h8ESK8Q2fCK",
        "outputId": "b77e1f82-daa1-444c-ca47-15c28a3f9c4f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 17:44, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.439800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.520400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.395900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.442800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.443800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.390700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.399400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.527000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.409300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.424700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.416100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.399900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.367400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.375600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.358600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.337100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.349500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.355400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.327700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.362200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.338600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.338200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.345600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.369400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.368900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.375900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.337000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.3860903787612915, metrics={'train_runtime': 1076.0333, 'train_samples_per_second': 0.743, 'train_steps_per_second': 0.093, 'total_flos': 161505233436672.0, 'train_loss': 0.3860903787612915, 'epoch': 2.02})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "kGa23hXnCSTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8dc953-64df-4518-ca44-9d85798d692d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "              (k_proj): QuantLinear(\n",
              "                (base_layer): QuantLinear()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (quant_linear_module): QuantLinear()\n",
              "              )\n",
              "              (o_proj): QuantLinear(\n",
              "                (base_layer): QuantLinear()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (quant_linear_module): QuantLinear()\n",
              "              )\n",
              "              (q_proj): QuantLinear(\n",
              "                (base_layer): QuantLinear()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (quant_linear_module): QuantLinear()\n",
              "              )\n",
              "              (v_proj): QuantLinear(\n",
              "                (base_layer): QuantLinear()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (quant_linear_module): QuantLinear()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (act_fn): SiLU()\n",
              "              (down_proj): QuantLinear()\n",
              "              (gate_proj): QuantLinear()\n",
              "              (up_proj): QuantLinear()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the model"
      ],
      "metadata": {
        "id": "9Vzi4kNj3YuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(\"output_dirc\")"
      ],
      "metadata": {
        "id": "CWPTQkQb3QHx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from huggingface_hub import login\n",
        "#login()"
      ],
      "metadata": {
        "id": "ar8r3KBi3XQz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.push_to_hub(\"HTML-finetunined-WORK-A\")"
      ],
      "metadata": {
        "id": "VLNtM3sy389D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the fine-tuned model from local"
      ],
      "metadata": {
        "id": "E_F_EzVx4SjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/output_dirc\""
      ],
      "metadata": {
        "id": "zsEuZZC94U8G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gptq_config = GPTQConfig(bits=4, use_exllama=False)\n",
        "\n",
        "trained_model = AutoModelForCausalLM.from_pretrained(\n",
        "output_dir, local_files_only=True,\n",
        "quantization_config=gptq_config,\n",
        "trust_remote_code=True, device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be5A_SnY5A-n",
        "outputId": "d1225e8d-ea9c-4057-dc0e-15caa0f48511"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the model"
      ],
      "metadata": {
        "id": "C5Y_unjxA5ZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run model and compare to expected answer"
      ],
      "metadata": {
        "id": "40kJ2vwKJCHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_question = data_split[\"test\"]['instruction'][2]\n",
        "generated_answer = inference(test_question, trained_model, tokenizer)\n",
        "print(test_question)\n",
        "print(generated_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BEhkp54BHCT",
        "outputId": "8ef45c61-185a-46e1-f830-8c84860104f5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create a simple HTML webpage without using any external stylesheets.\n",
            "\n",
            "\n",
            "```\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "  <title>My Page</title>\n",
            "</head>\n",
            "<body>\n",
            "  <h1>Hello World!</h1>\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "This is a basic HTML page without any external stylesheets. It contains a single heading element with the text \"Hello World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = data_split[\"test\"]['output'][2]\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZxxqeXkHIlt",
        "outputId": "e536b82c-fd06-434e-cd04-029f9a1516cf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            "<head>\n",
            "  <title>My Web Page</title>\n",
            "</head>\n",
            "<body>\n",
            "  <h1>Welcome to My Web Page</h1>\n",
            "  <p>This is my first web page.</p>\n",
            "</body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exact_match = is_exact_match(generated_answer, answer)\n",
        "print(exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILpvW63rHiln",
        "outputId": "9a4b8ef2-a3b9-4bb9-ceca-b4195c9f7808"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run over entire dataset and compare"
      ],
      "metadata": {
        "id": "OTEFkmF6Hotz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Hn8lAdpXHziX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing Variables:\n",
        "n = 20\n",
        "metrics = {'exact_matches': []}\n",
        "predictions = []\n",
        "\n",
        "#Iterating through Test Data\n",
        "\n",
        "for i, item in tqdm(enumerate(data_split[\"test\"])):\n",
        "    print(\"i Evaluating: \" + str(item))\n",
        "    instruction = item['instruction']\n",
        "    output = item['output']\n",
        "\n",
        " #Generating Predictions\n",
        "    try:\n",
        "      predicted_output = inference(instruction, trained_model, tokenizer)\n",
        "    except:\n",
        "      continue\n",
        "    predictions.append([predicted_output, output])\n",
        "\n",
        "  #Calculating Exact Match Metric\n",
        "    #fixed: exact_match = is_exact_match(generated_output, output)\n",
        "    exact_match = is_exact_match(predicted_output, output)\n",
        "    metrics['exact_matches'].append(exact_match)\n",
        "\n",
        "   #Terminating Early (Optional)\n",
        "    if i > n and n != -1:\n",
        "      break\n",
        "print('Number of exact matches: ', sum(metrics['exact_matches']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ5r6rsuHnG3",
        "outputId": "cb9b8b8e-7ffb-491c-e858-5d3edcce1ff0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n <head>\\n  <title>My Webpage</title>\\n  <meta http-equiv=\"refresh\" content=\"5\">\\n </head>\\n <body>\\n  Hello World!\\n </body>\\n</html>', 'input': '<html>\\n <head>\\n  <title>My Webpage</title>\\n </head>\\n <body>\\n  Hello World!\\n </body>\\n</html>', 'instruction': 'Update the following HTML page so that it refreshes the page every 5 seconds.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 6422, 278, 1494, 4544, 1813, 577, 393, 372, 11086, 267, 278, 1813, 1432, 29871, 29945, 6923, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 529, 2813, 29958, 13, 29871, 529, 3257, 29958, 3421, 2563, 3488, 829, 3257, 29958, 13, 29871, 529, 7299, 1732, 29899, 9402, 543, 22379, 29908, 2793, 543, 29945, 1013, 13, 1533, 2813, 29958, 13, 529, 2587, 29958, 13, 29871, 15043, 2787, 29991, 13, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r1it [00:07,  7.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>My HTML Page</title>\\n</head>\\n<body>\\n  <h1>My HTML Page</h1>\\n  <p>This is a basic HTML page with a heading and a paragraph of text.</p> \\n</body>\\n</html>', 'input': '', 'instruction': 'Create a basic HTML page with a heading and a paragraph of text.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 263, 6996, 4544, 1813, 411, 263, 28435, 322, 263, 14880, 310, 1426, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 29871, 529, 3257, 29958, 3421, 4544, 9305, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 29871, 529, 29882, 29896, 29958, 3421, 4544, 9305, 829, 29882, 29896, 29958, 13, 29871, 529, 29886, 29958, 4013, 338, 263, 6996, 4544, 1813, 411, 263, 28435, 322, 263, 14880, 310, 1426, 21106, 29886, 29958, 29871, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:14,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n<head>\\n  <title>My Web Page</title>\\n</head>\\n<body>\\n  <h1>Welcome to My Web Page</h1>\\n  <p>This is my first web page.</p>\\n</body>\\n</html>', 'input': '', 'instruction': 'Create a simple HTML webpage without using any external stylesheets.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 263, 2560, 4544, 24499, 1728, 773, 738, 7029, 11949, 354, 1691, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 29871, 529, 3257, 29958, 3421, 2563, 9305, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 29871, 529, 29882, 29896, 29958, 28862, 2763, 304, 1619, 2563, 9305, 829, 29882, 29896, 29958, 13, 29871, 529, 29886, 29958, 4013, 338, 590, 937, 1856, 1813, 21106, 29886, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:22,  7.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n <meta charset=\"UTF-8\">\\n <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n <title>Array values</title>\\n</head>\\n<body>\\n <ul>\\n   <% for (let i = 0; i < arr.length; i++) { %>\\n        <li><%= arr[i] %></li>\\n   <% } %>\\n </ul>\\n</body>\\n</html>', 'input': 'arr = [1, 2, 3, 4, 5]', 'instruction': 'Using an array, create a web page that prints out all of the array elements.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 15156, 385, 1409, 29892, 1653, 263, 1856, 1813, 393, 14677, 714, 599, 310, 278, 1409, 3161, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 6361, 543, 264, 1013, 13, 29966, 2813, 29958, 13, 529, 7299, 17425, 543, 10496, 29899, 29947, 1013, 13, 529, 7299, 1024, 543, 1493, 637, 29908, 2793, 543, 2103, 29922, 10141, 29899, 2103, 29892, 2847, 29899, 7052, 29922, 29896, 29889, 29900, 1013, 13, 529, 3257, 29958, 2588, 1819, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 529, 352, 29958, 13, 259, 20577, 363, 313, 1026, 474, 353, 29871, 29900, 29936, 474, 529, 3948, 29889, 2848, 29936, 474, 4862, 426, 6580, 13, 4706, 529, 492, 5299, 12222, 3948, 29961, 29875, 29962, 1273, 2565, 492, 29958, 13, 259, 20577, 500, 6580, 13, 1533, 352, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:29,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n<head>\\n<style>\\n.container {\\n    width: 300px;\\n    height: 200px;\\n    background-color: blue;\\n}\\n\\n.text {\\n    color: white;\\n    font-family: Arial;\\n    font-size: 16px;\\n    padding: 15px;\\n    text-align: center;\\n}\\n</style>\\t\\n</head>\\n\\n<body>\\n\\n<div class=\"container\">\\n  <div class=\"text\">Hello World!</div>\\n</div>\\n\\n</body>\\n</html>', 'input': 'CSS Classes:\\n\\n.container {\\n    width: 300px;\\n    height: 200px;\\n    background-color: blue;\\n}\\n\\n.text {\\n    color: white;\\n    font-family: Arial;\\n    font-size: 16px;\\n    padding: 15px;\\n    text-align: center;\\n}', 'instruction': 'Build a HTML page using the given CSS class', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 8893, 263, 4544, 1813, 773, 278, 2183, 6783, 770, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 29966, 3293, 29958, 13, 29889, 7611, 426, 13, 1678, 2920, 29901, 29871, 29941, 29900, 29900, 1756, 29936, 13, 1678, 3171, 29901, 29871, 29906, 29900, 29900, 1756, 29936, 13, 1678, 3239, 29899, 2780, 29901, 7254, 29936, 13, 29913, 13, 13, 29889, 726, 426, 13, 1678, 2927, 29901, 4796, 29936, 13, 1678, 4079, 29899, 11922, 29901, 319, 9315, 29936, 13, 1678, 4079, 29899, 2311, 29901, 29871, 29896, 29953, 1756, 29936, 13, 1678, 7164, 29901, 29871, 29896, 29945, 1756, 29936, 13, 1678, 1426, 29899, 2520, 29901, 4818, 29936, 13, 29913, 13, 829, 3293, 29958, 12, 13, 829, 2813, 29958, 13, 13, 29966, 2587, 29958, 13, 13, 29966, 4563, 770, 543, 7611, 1013, 13, 29871, 529, 4563, 770, 543, 726, 1013, 10994, 2787, 29991, 829, 4563, 29958, 13, 829, 4563, 29958, 13, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:37,  7.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n  <head>\\n    <title>Test</title>\\n  </head>\\n  <body>\\n    <h1>My Heading</h1>\\n    <p>This is a test.\\n  </body>\\n</html>', 'input': '', 'instruction': 'Write a number of HTML tags such that their end tags are mismatched.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 6113, 263, 1353, 310, 4544, 8282, 1316, 393, 1009, 1095, 8282, 526, 29635, 287, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29871, 529, 2813, 29958, 13, 1678, 529, 3257, 29958, 3057, 829, 3257, 29958, 13, 29871, 1533, 2813, 29958, 13, 29871, 529, 2587, 29958, 13, 1678, 529, 29882, 29896, 29958, 3421, 940, 9382, 829, 29882, 29896, 29958, 13, 1678, 529, 29886, 29958, 4013, 338, 263, 1243, 29889, 13, 29871, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:44,  7.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': \"<html>\\n<body>\\n   <script>\\n\\t  function onPageLoad() {\\n\\t\\t  var name = prompt('Please enter your name: ');\\n\\t\\t  alert('Welcome ' + name + '!');\\n\\t  }\\n\\t  onPageLoad();\\n   </script>\\n</body>\\n</html>\", 'input': '', 'instruction': 'Create a HTML page that takes your name as input and welcomes you on page load.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 263, 4544, 1813, 393, 4893, 596, 1024, 408, 1881, 322, 5476, 26807, 366, 373, 1813, 2254, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29966, 2587, 29958, 13, 259, 529, 2154, 29958, 13, 12, 29871, 740, 373, 5074, 5896, 580, 426, 13, 12, 12, 29871, 722, 1024, 353, 9508, 877, 12148, 3896, 596, 1024, 29901, 525, 416, 13, 12, 12, 29871, 6655, 877, 28862, 2763, 525, 718, 1024, 718, 525, 29991, 2157, 13, 12, 29871, 500, 13, 12, 29871, 373, 5074, 5896, 890, 13, 259, 1533, 2154, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:52,  7.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n  <body>\\n    <form>\\n      <input type=\"checkbox\" />\\n    </form>\\n  </body>\\n</html>', 'input': '', 'instruction': 'Create an HTML page with a form containing a checkbox.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 385, 4544, 1813, 411, 263, 883, 6943, 263, 12527, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29871, 529, 2587, 29958, 13, 1678, 529, 689, 29958, 13, 418, 529, 2080, 1134, 543, 12348, 29908, 2900, 13, 1678, 1533, 689, 29958, 13, 29871, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [01:00,  7.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>Hunted Maze</title>\\n  <style>\\n    * {\\n      box-sizing: border-box;\\n    }\\n    body{\\n      font-family: sans-serif;\\n      background-color: #eee;\\n      text-align: center;\\n      padding: 20px;\\n    }\\n    h1 {\\n      font-size: 2rem;\\n      color: #444;\\n    }\\n    .maze {\\n      position: relative;\\n      width: 800px;\\n      height: 600px;\\n      background-color: #f0f0f0;\\n      border-radius: 8px;\\n    }\\n    .box {\\n      position: absolute;\\n      width: 25px;\\n      height: 25px;\\n      background-color: #444;\\n      border-radius: 4px;\\n      top: 0;\\n      left: 0;\\n    }\\n  </style>\\n</head>\\n<body>\\n  <h1>Hunted Maze</h1>\\n  <div class=\"maze\">\\n    <div class=\"box\"></div>\\n  </div>\\n  <script>\\n    // add logic for the game\\n\\n  </script>\\n</body>\\n</html>', 'input': '', 'instruction': 'Design an interactive game using HTML, CSS and JavaScript.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4002, 647, 385, 28923, 3748, 773, 4544, 29892, 6783, 322, 8286, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 29871, 529, 3257, 29958, 29950, 28000, 17326, 29872, 829, 3257, 29958, 13, 29871, 529, 3293, 29958, 13, 1678, 334, 426, 13, 418, 3800, 29899, 29879, 5281, 29901, 5139, 29899, 1884, 29936, 13, 1678, 500, 13, 1678, 3573, 29912, 13, 418, 4079, 29899, 11922, 29901, 7209, 29899, 643, 361, 29936, 13, 418, 3239, 29899, 2780, 29901, 396, 3905, 29872, 29936, 13, 418, 1426, 29899, 2520, 29901, 4818, 29936, 13, 418, 7164, 29901, 29871, 29906, 29900, 1756, 29936, 13, 1678, 500, 13, 1678, 298, 29896, 426, 13, 418, 4079, 29899, 2311, 29901, 29871, 29906, 1745, 29936, 13, 418, 2927, 29901, 396, 29946, 29946, 29946, 29936, 13, 1678, 500, 13, 1678, 869, 655, 911, 426, 13, 418, 2602, 29901, 6198, 29936, 13, 418, 2920, 29901, 29871, 29947, 29900, 29900, 1756, 29936, 13, 418, 3171, 29901, 29871, 29953, 29900, 29900, 1756, 29936, 13, 418, 3239, 29899, 2780, 29901, 396, 29888, 29900, 29888, 29900, 29888, 29900, 29936, 13, 418, 5139, 29899, 13471, 29901, 29871, 29947, 1756, 29936, 13, 1678, 500, 13, 1678, 869, 1884, 426, 13, 418, 2602, 29901, 8380, 29936, 13, 418, 2920, 29901, 29871, 29906, 29945, 1756, 29936, 13, 418, 3171, 29901, 29871, 29906, 29945, 1756, 29936, 13, 418, 3239, 29899, 2780, 29901, 396, 29946, 29946, 29946, 29936, 13, 418, 5139, 29899, 13471, 29901, 29871, 29946, 1756, 29936, 13, 418, 2246, 29901, 29871, 29900, 29936, 13, 418, 2175, 29901, 29871, 29900, 29936, 13, 1678, 500, 13, 29871, 1533, 3293, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 29871, 529, 29882, 29896, 29958, 29950, 28000, 17326, 29872, 829, 29882, 29896, 29958, 13, 29871, 529, 4563, 770, 543, 655, 911, 1013, 13, 1678, 529, 4563, 770, 543, 1884, 5319, 4563, 29958, 13, 29871, 1533, 4563, 29958, 13, 29871, 529, 2154, 29958, 13, 1678, 849, 788, 5900, 363, 278, 3748, 13, 13, 29871, 1533, 2154, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [01:08,  7.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html>\\n  <head>\\n    <title>My Page</title>\\n  </head>\\n  <body>\\n    <h1>My Page</h1>\\n    <p>This is my first HTML page.</p>\\n    <img src=\"sample-image.jpg\" alt=\"sample image\">\\n  </body>\\n</html>', 'input': '', 'instruction': 'Construct a basic HTML page that renders a heading, a description of the page, and a photo.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 1168, 4984, 263, 6996, 4544, 1813, 393, 7697, 414, 263, 28435, 29892, 263, 6139, 310, 278, 1813, 29892, 322, 263, 15373, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 29958, 13, 29871, 529, 2813, 29958, 13, 1678, 529, 3257, 29958, 3421, 9305, 829, 3257, 29958, 13, 29871, 1533, 2813, 29958, 13, 29871, 529, 2587, 29958, 13, 1678, 529, 29882, 29896, 29958, 3421, 9305, 829, 29882, 29896, 29958, 13, 1678, 529, 29886, 29958, 4013, 338, 590, 937, 4544, 1813, 21106, 29886, 29958, 13, 1678, 529, 2492, 4765, 543, 11249, 29899, 3027, 29889, 6173, 29908, 5272, 543, 11249, 1967, 1013, 13, 29871, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [01:15,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n  <head>\\n    <!-- Include the script -->\\n    <script src=\"alert.js\"></script>\\n  </head>\\n  <body>\\n    <button id=\"btnAlert\" onclick=\"alertFunction()\">Alert</button>\\n  </body>\\n</html>\\n\\n// alert.js\\n\\nfunction alertFunction() {\\n  alert(\"This is an alert!\");\\n}', 'input': '', 'instruction': 'Write an HTML page that displays a Javascript alert when a button is clicked.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 6113, 385, 4544, 1813, 393, 14423, 263, 12728, 6655, 746, 263, 2826, 338, 11484, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29871, 529, 2813, 29958, 13, 1678, 10341, 512, 2325, 278, 2471, 6660, 13, 1678, 529, 2154, 4765, 543, 12888, 29889, 1315, 5319, 2154, 29958, 13, 29871, 1533, 2813, 29958, 13, 29871, 529, 2587, 29958, 13, 1678, 529, 3092, 1178, 543, 7290, 16649, 29908, 15630, 543, 12888, 6678, 580, 1013, 16649, 829, 3092, 29958, 13, 29871, 1533, 2587, 29958, 13, 829, 1420, 29958, 13, 13, 458, 6655, 29889, 1315, 13, 13, 2220, 6655, 6678, 580, 426, 13, 29871, 6655, 703, 4013, 338, 385, 6655, 24862, 13, 29913], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [01:23,  7.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n    <head>\\n        <title>Page Title</title>\\n    </head>\\n    <body class=\"main\">\\n    </body>\\n</html>', 'input': '<html>\\n    <head>\\n        <title>Page Title</title>\\n    </head>\\n</html>', 'instruction': \"Edit the following HTML code snippet to give the <body> tag the class 'main'.\", 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 6103, 278, 1494, 4544, 775, 11534, 304, 2367, 278, 529, 2587, 29958, 4055, 278, 770, 525, 3396, 4286, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 1678, 529, 2813, 29958, 13, 4706, 529, 3257, 29958, 5074, 18527, 829, 3257, 29958, 13, 1678, 1533, 2813, 29958, 13, 1678, 529, 2587, 770, 543, 3396, 1013, 13, 1678, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [01:30,  7.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html>\\n<head>\\n <title>My Web Page</title>\\n</head>\\n<body>\\n <h1>This is my title</h1>\\n <p>This is some content.</p>\\n <button>Click Me!</button>\\n</body>\\n</html>', 'input': '', 'instruction': 'Design a web page in HTML5 with a heading, a paragraph and a button.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4002, 647, 263, 1856, 1813, 297, 4544, 29945, 411, 263, 28435, 29892, 263, 14880, 322, 263, 2826, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 529, 3257, 29958, 3421, 2563, 9305, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 529, 29882, 29896, 29958, 4013, 338, 590, 3611, 829, 29882, 29896, 29958, 13, 529, 29886, 29958, 4013, 338, 777, 2793, 21106, 29886, 29958, 13, 529, 3092, 29958, 4164, 2191, 29991, 829, 3092, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [01:38,  7.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html>\\n   <head>\\n      <title>RandomBackground</title>\\n      <script>\\n         window.addEventListener(\"load\",function(){\\n            var randomColor = \"#\"+((1<<24)*Math.random()|0).toString(16);\\n            document.querySelector(\"body\").style.background = randomColor;\\n         });\\n      </script>\\n   </head>\\n   <body>\\n   </body>\\n</html>', 'input': '', 'instruction': 'Create an HTML page where the main content area has a random background color when the page is loaded.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 385, 4544, 1813, 988, 278, 1667, 2793, 4038, 756, 263, 4036, 3239, 2927, 746, 278, 1813, 338, 7500, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 29958, 13, 259, 529, 2813, 29958, 13, 418, 529, 3257, 29958, 17875, 10581, 829, 3257, 29958, 13, 418, 529, 2154, 29958, 13, 308, 3474, 29889, 16592, 703, 1359, 613, 2220, 4923, 13, 9651, 722, 4036, 3306, 353, 12305, 17969, 3552, 29896, 9314, 29906, 29946, 11877, 11309, 29889, 8172, 580, 29989, 29900, 467, 7711, 29898, 29896, 29953, 416, 13, 9651, 1842, 29889, 18825, 703, 2587, 2564, 3293, 29889, 7042, 353, 4036, 3306, 29936, 13, 308, 2604, 13, 418, 1533, 2154, 29958, 13, 259, 1533, 2813, 29958, 13, 259, 529, 2587, 29958, 13, 259, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [01:45,  7.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n <meta charset=\"UTF-8\">\\n <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n <title>Login Form</title>\\n</head>\\n<body>\\n <form>\\n  <label>Username:</label>\\n  <input type=\"text\" name=\"username\" required>\\n  <label>Password:</label>\\n  <input type=\"password\" name=\"password\" required>\\n  <input type=\"submit\" value=\"Login\">\\n </form>\\n</body>\\n</html>', 'input': '', 'instruction': 'Design a user interface in HTML for a login form.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4002, 647, 263, 1404, 5067, 297, 4544, 363, 263, 6464, 883, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 6361, 543, 264, 1013, 13, 29966, 2813, 29958, 13, 529, 7299, 17425, 543, 10496, 29899, 29947, 1013, 13, 529, 7299, 1024, 543, 1493, 637, 29908, 2793, 543, 2103, 29922, 10141, 29899, 2103, 29892, 2847, 29899, 7052, 29922, 29896, 29889, 29900, 1013, 13, 529, 3257, 29958, 11049, 3812, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 529, 689, 29958, 13, 29871, 529, 1643, 29958, 20249, 29901, 829, 1643, 29958, 13, 29871, 529, 2080, 1134, 543, 726, 29908, 1024, 543, 6786, 29908, 3734, 29958, 13, 29871, 529, 1643, 29958, 10048, 29901, 829, 1643, 29958, 13, 29871, 529, 2080, 1134, 543, 5630, 29908, 1024, 543, 5630, 29908, 3734, 29958, 13, 29871, 529, 2080, 1134, 543, 7892, 29908, 995, 543, 11049, 1013, 13, 1533, 689, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [01:53,  7.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n    <head></head>\\n    <body>\\n        <input type=\"text\" id=\"textbox\">\\n        <button onclick=\"sayHello()\">Say Hello</button>\\n        <p id=\"message\">Hello World!</p>\\n        \\n        <script>\\n            function sayHello() {\\n                var text = document.getElementById(\\'textbox\\').value;\\n                document.getElementById(\\'message\\').innerHTML = \"Hello \" + text + \"!\";\\n            }\\n        </script>\\n    </body>\\n</html>', 'input': '', 'instruction': 'Create a HTML page with a textbox, button and a message “Hello World!”', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 263, 4544, 1813, 411, 263, 18932, 29892, 2826, 322, 263, 2643, 1346, 10994, 2787, 8530, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 1678, 529, 2813, 2565, 2813, 29958, 13, 1678, 529, 2587, 29958, 13, 4706, 529, 2080, 1134, 543, 726, 29908, 1178, 543, 726, 1884, 1013, 13, 4706, 529, 3092, 15630, 543, 20834, 10994, 580, 1013, 29903, 388, 15043, 829, 3092, 29958, 13, 4706, 529, 29886, 1178, 543, 4906, 1013, 10994, 2787, 29991, 829, 29886, 29958, 13, 308, 13, 4706, 529, 2154, 29958, 13, 9651, 740, 1827, 10994, 580, 426, 13, 18884, 722, 1426, 353, 1842, 29889, 7119, 877, 726, 1884, 2824, 1767, 29936, 13, 18884, 1842, 29889, 7119, 877, 4906, 2824, 14742, 353, 376, 10994, 376, 718, 1426, 718, 376, 29991, 1769, 13, 9651, 500, 13, 4706, 1533, 2154, 29958, 13, 1678, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [02:02,  8.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n <head>\\n  <title>Styled Page</title>\\n  <style type=\"text/css\">\\n    body {\\n        background-color: white;\\n    }\\n    h1 {\\n        font-family: \\'Arial\\', sans-serif;\\n        font-size: 30px;\\n        color: black;\\n        text-align: center;\\n    }\\n  </style>\\n </head>\\n <body>\\n  <h1>Styled Page</h1>\\n </body>\\n</html>', 'input': '<html>\\n <head>\\n  <title>Styled Page</title>\\n </head>\\n <body>\\n  <h1>Styled Page</h1>\\n </body>\\n</html>', 'instruction': 'Modify the CSS in the given HTML code to style the web page', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 2111, 1598, 278, 6783, 297, 278, 2183, 4544, 775, 304, 3114, 278, 1856, 1813, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 529, 2813, 29958, 13, 29871, 529, 3257, 29958, 855, 29891, 839, 9305, 829, 3257, 29958, 13, 29871, 529, 3293, 1134, 543, 726, 29914, 4268, 1013, 13, 1678, 3573, 426, 13, 4706, 3239, 29899, 2780, 29901, 4796, 29936, 13, 1678, 500, 13, 1678, 298, 29896, 426, 13, 4706, 4079, 29899, 11922, 29901, 525, 29909, 9315, 742, 7209, 29899, 643, 361, 29936, 13, 4706, 4079, 29899, 2311, 29901, 29871, 29941, 29900, 1756, 29936, 13, 4706, 2927, 29901, 4628, 29936, 13, 4706, 1426, 29899, 2520, 29901, 4818, 29936, 13, 1678, 500, 13, 29871, 1533, 3293, 29958, 13, 1533, 2813, 29958, 13, 529, 2587, 29958, 13, 29871, 529, 29882, 29896, 29958, 855, 29891, 839, 9305, 829, 29882, 29896, 29958, 13, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [02:15,  9.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n    <head>\\n        <title>Welcome to my website!</title>\\n    </head>\\n    <body>\\n        <h1>Welcome to my website!</h1>\\n    </body>\\n</html>', 'input': '\"Welcome to my website!\"', 'instruction': 'Create a HTML page that prints the following message', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 263, 4544, 1813, 393, 14677, 278, 1494, 2643, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 1678, 529, 2813, 29958, 13, 4706, 529, 3257, 29958, 28862, 2763, 304, 590, 4700, 29991, 829, 3257, 29958, 13, 1678, 1533, 2813, 29958, 13, 1678, 529, 2587, 29958, 13, 4706, 529, 29882, 29896, 29958, 28862, 2763, 304, 590, 4700, 29991, 829, 29882, 29896, 29958, 13, 1678, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [02:23,  8.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n  <meta charset=\"UTF-8\">\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n  <title>Title</title>\\n</head>\\n<body>\\n  <h1>Home</h1>\\n  <h1>About</h1>\\n</body>\\n</html>', 'input': '', 'instruction': 'Write an HTML page with two headings \"Home\" and \"About\".', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 6113, 385, 4544, 1813, 411, 1023, 2343, 886, 376, 11184, 29908, 322, 376, 28173, 1642, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 6361, 543, 264, 1013, 13, 29966, 2813, 29958, 13, 29871, 529, 7299, 17425, 543, 10496, 29899, 29947, 1013, 13, 29871, 529, 7299, 1024, 543, 1493, 637, 29908, 2793, 543, 2103, 29922, 10141, 29899, 2103, 29892, 2847, 29899, 7052, 29922, 29896, 29889, 29900, 1013, 13, 29871, 529, 3257, 29958, 7030, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 29871, 529, 29882, 29896, 29958, 11184, 829, 29882, 29896, 29958, 13, 29871, 529, 29882, 29896, 29958, 28173, 829, 29882, 29896, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [02:31,  8.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n<head>\\n    <title>My Details</title>\\n</head>\\n<body>\\n    <table>\\n        <tr>\\n            <th>Name</th>\\n            <th>Age</th>  \\n            <th>Occupation</th>  \\n        </tr>\\n        <tr>\\n            <td> Joe Doe</td>\\n            <td> 25 </td>\\n            <td> Web Developer </td>\\n        </tr>\\n    </table>\\n</body>\\n</html>', 'input': '', 'instruction': 'Create a HTML page displaying a simple table showing your name, age and occupation.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 4391, 263, 4544, 1813, 16384, 263, 2560, 1591, 6445, 596, 1024, 29892, 5046, 322, 26818, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 1678, 529, 3257, 29958, 3421, 25577, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 1678, 529, 2371, 29958, 13, 4706, 529, 509, 29958, 13, 9651, 529, 386, 29958, 1170, 829, 386, 29958, 13, 9651, 529, 386, 29958, 22406, 829, 386, 29958, 259, 13, 9651, 529, 386, 29958, 22034, 786, 362, 829, 386, 29958, 259, 13, 4706, 1533, 509, 29958, 13, 4706, 529, 509, 29958, 13, 9651, 529, 1594, 29958, 11131, 1938, 29872, 829, 1594, 29958, 13, 9651, 529, 1594, 29958, 29871, 29906, 29945, 1533, 1594, 29958, 13, 9651, 529, 1594, 29958, 2563, 10682, 261, 1533, 1594, 29958, 13, 4706, 1533, 509, 29958, 13, 1678, 1533, 2371, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [02:39,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<!DOCTYPE html>\\n<html>\\n<head>\\n <title>Sample Form</title>\\n</head>\\n<body>\\n  <form action=\"\" method=\"post\">\\n   <input type=\"text\" placeholder=\"Input...\"/>\\n   <input type=\"submit\" value=\"Submit\" />\\n  </form>\\n</body>\\n</html>', 'input': '', 'instruction': 'Construct a HTML page that displays a form with a text field and a submit button.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 1168, 4984, 263, 4544, 1813, 393, 14423, 263, 883, 411, 263, 1426, 1746, 322, 263, 9752, 2826, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 29991, 21300, 3472, 29958, 13, 29966, 1420, 29958, 13, 29966, 2813, 29958, 13, 529, 3257, 29958, 17708, 3812, 829, 3257, 29958, 13, 829, 2813, 29958, 13, 29966, 2587, 29958, 13, 29871, 529, 689, 3158, 13776, 1158, 543, 2490, 1013, 13, 259, 529, 2080, 1134, 543, 726, 29908, 12983, 543, 4290, 856, 4681, 13, 259, 529, 2080, 1134, 543, 7892, 29908, 995, 543, 16228, 29908, 2900, 13, 29871, 1533, 689, 29958, 13, 829, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [02:47,  8.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i Evaluating: {'output': '<html>\\n    <head>\\n    </head>\\n    <body>\\n        <form>\\n            <label>Name: </label><input type=\"text\" name=\"name\"><br>\\n            <label>Age: </label><input type=\"text\" name=\"age\"><br>\\n            <input type=\"submit\" value=\"Submit\">\\n        </form>\\n    </body>\\n</html>', 'input': '', 'instruction': 'Develop an HTML form which includes two input fields, an label and a submit button.', 'input_ids': [1, 13866, 338, 15278, 393, 16612, 263, 3414, 304, 775, 297, 4544, 29892, 5816, 338, 1962, 297, 4544, 29901, 29871, 13, 29871, 13, 29915, 2277, 29937, 2799, 4080, 29901, 29871, 13, 21956, 385, 4544, 883, 607, 7805, 1023, 1881, 4235, 29892, 385, 3858, 322, 263, 9752, 2826, 29889, 13, 835, 13291, 29901, 29871, 13, 29966, 1420, 29958, 13, 1678, 529, 2813, 29958, 13, 1678, 1533, 2813, 29958, 13, 1678, 529, 2587, 29958, 13, 4706, 529, 689, 29958, 13, 9651, 529, 1643, 29958, 1170, 29901, 1533, 1643, 5299, 2080, 1134, 543, 726, 29908, 1024, 543, 978, 3254, 1182, 29958, 13, 9651, 529, 1643, 29958, 22406, 29901, 1533, 1643, 5299, 2080, 1134, 543, 726, 29908, 1024, 543, 482, 3254, 1182, 29958, 13, 9651, 529, 2080, 1134, 543, 7892, 29908, 995, 543, 16228, 1013, 13, 4706, 1533, 689, 29958, 13, 1678, 1533, 2587, 29958, 13, 829, 1420, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [02:54,  8.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of exact matches:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ZERO!! This metric for evaluation is not useful for this dataset"
      ],
      "metadata": {
        "id": "OPnjoBgVzOrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(predictions, columns=[\"predicted_answer\", \"target_answer\"])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMs-S10JGTG",
        "outputId": "6b2f7d5c-f32b-42da-c80c-bd47b17129cd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     predicted_answer  \\\n",
            "0   \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "1   \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "2   \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "3   \\n\\nExample:\\n\\nconst myArray = [1, 2, 3, 4, 5...   \n",
            "4   \\n\\n```\\n<div class=\"example\">\\n  <p>This is a...   \n",
            "5   \\n\\nExample:\\n<div>\\n  <p>Hello World!</p>\\n</...   \n",
            "6   \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "7   \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "8   \\n\\nDesign an interactive game using HTML, CSS...   \n",
            "9   \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "10  \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "11  \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "12  \\n\\nHere is the HTML code for the page:\\n\\n<!D...   \n",
            "13  \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "14  \\n\\nPlease design a user interface in HTML for...   \n",
            "15  \\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <t...   \n",
            "16  .\\n\\n<html>\\n  <head>\\n    <style>\\n      body...   \n",
            "17  : \"Hello, World!\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...   \n",
            "18  \\n\\n\\n<html>\\n  <head>\\n    <title>My Website<...   \n",
            "19  \\n\\nHere is an example of how you can create a...   \n",
            "20  \\n\\nHere is an example of a HTML page that dis...   \n",
            "21  \\n\\n```\\n<html>\\n  <head>\\n    <title>Form</ti...   \n",
            "\n",
            "                                        target_answer  \n",
            "0   <html>\\n <head>\\n  <title>My Webpage</title>\\n...  \n",
            "1   <!DOCTYPE html>\\n<html>\\n<head>\\n  <title>My H...  \n",
            "2   <html>\\n<head>\\n  <title>My Web Page</title>\\n...  \n",
            "3   <!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n <m...  \n",
            "4   <html>\\n<head>\\n<style>\\n.container {\\n    wid...  \n",
            "5   <html>\\n  <head>\\n    <title>Test</title>\\n  <...  \n",
            "6   <html>\\n<body>\\n   <script>\\n\\t  function onPa...  \n",
            "7   <html>\\n  <body>\\n    <form>\\n      <input typ...  \n",
            "8   <!DOCTYPE html>\\n<html>\\n<head>\\n  <title>Hunt...  \n",
            "9   <!DOCTYPE html>\\n<html>\\n  <head>\\n    <title>...  \n",
            "10  <html>\\n  <head>\\n    <!-- Include the script ...  \n",
            "11  <html>\\n    <head>\\n        <title>Page Title<...  \n",
            "12  <!DOCTYPE html>\\n<html>\\n<head>\\n <title>My We...  \n",
            "13  <!DOCTYPE html>\\n<html>\\n   <head>\\n      <tit...  \n",
            "14  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n <m...  \n",
            "15  <html>\\n    <head></head>\\n    <body>\\n       ...  \n",
            "16  <html>\\n <head>\\n  <title>Styled Page</title>\\...  \n",
            "17  <html>\\n    <head>\\n        <title>Welcome to ...  \n",
            "18  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n  <...  \n",
            "19  <html>\\n<head>\\n    <title>My Details</title>\\...  \n",
            "20  <!DOCTYPE html>\\n<html>\\n<head>\\n <title>Sampl...  \n",
            "21  <html>\\n    <head>\\n    </head>\\n    <body>\\n ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['predicted_answer'])"
      ],
      "metadata": {
        "id": "h2mLW6iq3iMf",
        "outputId": "bf3a24e5-7d68-4743-e667-6993ab630ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df['target_answer'])"
      ],
      "metadata": {
        "id": "t_aHbUuV4w3S",
        "outputId": "f5341047-59a7-4a97-e0c1-54a1b06a37b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation with Metric: chr_f"
      ],
      "metadata": {
        "id": "Cur3M43i6Dgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChrF is a evaluation metrics that use the F-score statistic for character n-gram matches. We use the implementation that is already present in sacrebleu"
      ],
      "metadata": {
        "id": "PL7Pbeo39lXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "vBWLY3qF1M7X",
        "outputId": "baf014e1-7ef5-461e-c7bb-f8945eabcaa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric  # For sacrebleu CHRF\n",
        "chrf = load_metric(\"chrf\")"
      ],
      "metadata": {
        "id": "3nNNHibZ3DdC",
        "outputId": "22f999cb-79b0-448f-8be2-4c8b63cf0944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "b5318b90b2dc437db5eef9efcd838340",
            "8cab0c818a7a488782cb11d79edafc43",
            "c523e1cee771448cae6d00c92d8d4dfd",
            "c6690a2cb60f4e66b4ad2f66bded1540",
            "ca855995b152403996565a9ca7f11491",
            "eb07ab0f0cab4485aea256f484a6c97f",
            "69b7bf6c5d5545a4bac9b2ebd5c678c2",
            "1f0659018fdd41798321cac84319dd1d",
            "436b3599f6dd422d8a032acd7c805440",
            "290cf3de8a3c40afae3d0bb464e14af7",
            "a018475e109c497c9d6951b2adae1840"
          ]
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-eb3fabc38259>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  chrf = load_metric(\"chrf\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for chrf contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.0/metrics/chrf/chrf.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.83k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5318b90b2dc437db5eef9efcd838340"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = df['predicted_answer'].tolist()  # Convert Series to list\n",
        "reference = df['target_answer'].tolist()  # Convert Series to list\n",
        "\n",
        "# Create a list of lists for reference (if needed)\n",
        "if not isinstance(reference[0], list):\n",
        "    reference = [[ref] for ref in reference]"
      ],
      "metadata": {
        "id": "pnZBGAfl3_EO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = chrf.compute(predictions=prediction, references=reference)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "llF_toM85ufx",
        "outputId": "c984a806-29f1-42ea-ea85-0a2da8e7a597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 40.14326320585296, 'char_order': 6, 'word_order': 0, 'beta': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#API Development"
      ],
      "metadata": {
        "id": "_cLh2tTx3X37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "# Install required libraries\n",
        "!pip install flask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAzIcEzGXe9q",
        "outputId": "2619ebf5-f426-49fc-c595-b3270ae98629"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from threading import Thread\n",
        "import atexit\n",
        "\n",
        "output_dir = '/content/output_dirc'\n",
        "gptq_config = GPTQConfig(bits=4, use_exllama= False)\n",
        "\n",
        "trained_model = AutoModelForCausalLM.from_pretrained(\n",
        "output_dir, local_files_only=True,\n",
        "quantization_config=gptq_config,\n",
        "trust_remote_code=True, device_map=\"auto\"\n",
        ")\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/generate_html', methods=['POST'])\n",
        "def generate_html():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        prompt = data['prompt']\n",
        "\n",
        "        generated_html = inference(instruction, trained_model, tokenizer)\n",
        "\n",
        "        return jsonify({'generated_html': generated_html})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)})\n",
        "\n",
        "def run_flask_app():\n",
        "    app.run(port=5000)\n",
        "\n",
        "# Run Flask app in the background\n",
        "flask_thread = Thread(target=run_flask_app)\n",
        "flask_thread.start()\n",
        "\n",
        "# Stop the server on exit\n",
        "atexit.register(lambda: app.shutdown())\n",
        "\n",
        "# The rest of your code for testing with requests can go here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3f5af5-5719-4a5e-e129-aca0ca3b728d",
        "id": "O2l1BNvI-3Hc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>()>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace with your actual prompt\n",
        "prompt = \"Generate HTML code for a simple webpage with a heading and a paragraph.\"\n",
        "\n",
        "# Define the JSON payload\n",
        "data = {\"prompt\": prompt}\n",
        "\n",
        "# Send the POST request to the Flask API\n",
        "response = requests.post(\"http://127.0.0.1:5000/generate_html\", json=data)\n",
        "\n",
        "# Print the response\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb8b23d-8f3c-40db-9465-4b1593c82f55",
        "id": "LWjEnhNa_Q7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2023 20:33:03] \"POST /generate_html HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'generated_html': '\\n\\n```\\n<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>My Webpage</title>\\n</head>\\n<body class=\"main\">\\n  <!-- Your content here -->\\n</body>\\n</html>\\n```\\n\\nAnswer: To give the \\\\begin{code}\\n<body>\\n\\\\end{code} tag the class'}\n"
          ]
        }
      ]
    }
  ]
}